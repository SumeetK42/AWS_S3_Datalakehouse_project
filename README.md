# üèóÔ∏è AWS S3 Data Lakehouse ‚Äî Stocks Analytics Pipeline

> An end-to-end serverless data lakehouse on AWS Cloud built for stock market data ingestion, transformation, and reporting using S3, Lambda, Glue and Athena

---

## üìê Architecture Overview

![High Level Architecture](High_Level_Arc.png)

The pipeline follows a **three-zone medallion architecture** ‚Äî Raw ‚Üí Processed ‚Üí Reporting ‚Äî orchestrated entirely via S3 events and AWS Lambda.

```
S3 (RAW)
  ‚îî‚îÄ‚ñ∫ Lambda Event ‚îÄ‚îÄ‚ñ∫ Glue Crawler + Athena Transformations
                            ‚îî‚îÄ‚ñ∫ S3 (PROCESSED)
                                  ‚îî‚îÄ‚ñ∫ Lambda Event ‚îÄ‚îÄ‚ñ∫ Glue Crawler + Athena Transformations
                                                            ‚îî‚îÄ‚ñ∫ S3 (REPORTING)
                                                                  ‚îî‚îÄ‚ñ∫ QuickSight (via Athena)
```

---

## ü™£ S3 Bucket Layout

The project uses a **single S3 bucket** with three logical zones as top-level folders:

```
s3://hyn-stocks-datalakehouse/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ stocks/
‚îÇ               ‚îî‚îÄ‚îÄ *.csv
‚îÇ
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ stocks/
‚îÇ       ‚îî‚îÄ‚îÄ year=YYYY/
‚îÇ           ‚îî‚îÄ‚îÄ month=MM/
‚îÇ               ‚îî‚îÄ‚îÄ *.parquet
‚îÇ
‚îî‚îÄ‚îÄ reporting/
    ‚îú‚îÄ‚îÄ monthly/
    ‚îÇ       ‚îî‚îÄ‚îÄ *.parquet
    ‚îî‚îÄ‚îÄ yearly/
        ‚îî‚îÄ‚îÄ *.parquet
```

---

## üóÑÔ∏è Athena Tables (hyn_stocks_db)

All tables are registered in the **`hyn_stocks_db`** Glue Data Catalog database.

### 1. `stocks_raw`
> Represents raw data landed in the RAW S3 zone. Crawled by Glue Crawler.
**S3 Location:** `s3://hyn-stocks-datalakehouse/raw/`

---

### 2. `stocks_processed`
> Partitioned, cleaned data in the PROCESSED zone. Enriched with year/month partition columns.
**S3 Location:** `s3://hyn-stocks-datalakehouse/processed/`

---

### 3. `monthly_stock_reporting`
> Aggregated monthly summary table used for trend analysis and dashboards.

**S3 Location:** `s3://hyn-stocks-datalakehouse/reporting/monthly/`

---

### 4. `yearly_stock_reporting`
> Aggregated yearly summary table for long-term trend visualization in Reporting.
**S3 Location:** `s3://hyn-stocks-datalakehouse/reporting/yearly/`

---

## ‚ö° Lambda Functions

### Lambda 1 ‚Äî RAW to PROCESSED (`lambda_raw_to_processed.py`)

**Trigger:** S3 Event Notification on `raw/` prefix (ObjectCreated)

**Responsibilities:**
- Reads raw CSV file from the RAW S3 zone.
- Parses and validates records
- Extracts `year` and `month` partition columns from the `date` field
- Writes partitioned data to the PROCESSED zone

**Flow:**
```
S3 PUT (raw/) ‚îÄ‚îÄ‚ñ∫ Lambda Trigger
                    ‚îú‚îÄ Read CSV from s3://‚Ä¶/raw/
                    ‚îú‚îÄ Transform + extract partitions
                    ‚îú‚îÄ Write to s3://‚Ä¶/processed/year=YYYY/month=MM/
                    ‚îî‚îÄ Update Athena partition on stocks_processed
```

---

### Lambda 2 ‚Äî PROCESSED to REPORTING (`lambda_processed_to_reporting.py`)

**Trigger:** S3 Event Notification on `processed/` prefix (ObjectCreated)

**Responsibilities:**
- Reads newly partitioned data from the PROCESSED zone
- Executes Athena aggregation queries to compute monthly and yearly summaries
- Writes aggregated results to the REPORTING zone
- Inserts/upserts records into `monthly_stock_reporting` and `yearly_stock_reporting`

**Flow:**
```
S3 PUT (processed/) ‚îÄ‚îÄ‚ñ∫ Lambda Trigger
                          ‚îú‚îÄ Run Athena monthly aggregation query
                          ‚îú‚îÄ Write results to s3://‚Ä¶/reporting/monthly/
                          ‚îú‚îÄ Run Athena yearly aggregation query
                          ‚îú‚îÄ Write results to s3://‚Ä¶/reporting/yearly/
                          ‚îî‚îÄ Repair partitions on reporting tables
```

---

## üöÄ Setup & Deployment Guide

### Prerequisites
- AWS Account with appropriate permissions
- AWS CLI configured
- Python 3.10+ (for Lambda runtime)
- S3 bucket created (e.g., `hyn-stocks-datalakehouse`)

---

### Step 1 ‚Äî S3 Bucket & Folder Setup

Create your S3 bucket and ensure the following top-level prefixes exist:
```
raw/
processed/
reporting/
```
> Refer to [`S3_Folders.png`](S3_Folders.png) for the expected structure.

---

### Step 2 ‚Äî IAM Role Setup

Create an IAM role for Lambda with the following managed policies:
- `AmazonS3FullAccess` (or a scoped-down custom policy for your bucket)
- `AmazonAthenaFullAccess`
- `AWSGlueServiceRole`
- `CloudWatchLogsFullAccess`

> Detailed role setup instructions: [`role_setup.md`](role_setup.md)

---

### Step 3 ‚Äî Glue Crawler Setup

1. Go to **AWS Glue ‚Üí Crawlers ‚Üí Create Crawler**
2. Create database: `hyn_stocks_db`
3. Set up crawlers that will be run automatically in Lamdba function

> Detailed crawler setup: [`crawler_setup.md`](crawler_setup.md)

---

### Step 4 ‚Äî Deploy Lambda Functions

1. Navigate to **AWS Lambda ‚Üí Create Function**
2. Choose **Author from scratch**, Python 3.10 runtime
3. Attach the IAM role created in Step 2
4. Upload the relevant script from the `Lambda Scripts/` folder
5. Set **S3 trigger** on the appropriate prefix:
   - Lambda 1: trigger on `raw/` prefix
   - Lambda 2: trigger on `processed/` prefix
6. Set **timeout** to at least 5 minutes (Athena queries can be slow)
7. Set **memory** to 512 MB or higher

---

### Step 5 ‚Äî Upload Dataset & Test

1. Upload CSV files from the `Dataset/` folder into `s3://‚Ä¶/raw/stocks/`
2. Lambda 1 will trigger ‚Üí data flows to `processed/`
3. Lambda 2 will trigger ‚Üí aggregated data flows to `reporting/`
4. Verify in Athena using the sample queries above

---

## üõ†Ô∏è AWS Services Used

| Service | Role |
|---|---|
| **Amazon S3** | Three-zone data lake storage (Raw / Processed / Reporting) |
| **AWS Lambda** | Serverless ETL orchestration triggered by S3 events |
| **AWS Glue Crawler** | Automatic schema discovery and Data Catalog updates |
| **AWS Glue Data Catalog** | Centralized metadata store for all Athena tables |
| **Amazon Athena** | SQL-based data transformation and aggregation |
| **AWS IAM** | Fine-grained access control for all services |
| **Amazon CloudWatch** | Lambda execution logs and monitoring |

---
